# cargar librerias
library(tidyverse)
library(cluster)
library(factoextra)
library(plotly)
library(dplyr)
# load dataset
df_mall <- read.csv('https://raw.githubusercontent.com/palasatenea66/DATASETS/main/Mall_Customers.csv')
# drop gender and customerID
df_mall <- select(df_mall, -Gender, -CustomerID)
# change column names
colnames(df_mall) <- c("Age", "Income", "Score")
head(df_mall)
str(df_mall)
colnames(df_mall)
#install.packages("fpc")
#install.packages("clusterCrit")
library(knitr)
metricas <- data.frame(Metrica = c("Silhouette ", "Elbow", "Calinski-Harabasz", "Davies-Bouldin"),
Buscar = c("Maximum value","Elbow point", "Maximum value","Minimum value"))
kable(metricas, caption = "Optimal Number of Clusters (k)")
library(fpc)
library(clusterCrit)
silhouette_scores <- c()
# Transform data into a numeric matrix of type double
data_matrix <- as.matrix(df_mall)
storage.mode(data_matrix) <- "double"
# Function to plot silhouette plots
plot_silhouette_custom <- function(data, clusters, k) {
dist_matrix <- dist(data)
sil <- silhouette(clusters, dist_matrix)
sil_df <- as.data.frame(sil[, 1:3])
colnames(sil_df) <- c("cluster", "neighbor", "sil_width")
sil_df$cluster <- as.factor(sil_df$cluster)
# Add an index for sorting
sil_df <- sil_df %>%
arrange(cluster, -sil_width) %>%
mutate(index = row_number())
ggplot(sil_df, aes(x = index, y = sil_width, fill = cluster)) +
geom_bar(stat = "identity", width = 1, color = "black", show.legend = FALSE) +
geom_hline(aes(yintercept = mean(sil_width)), color = "red", linetype = "dashed") +
labs(title = paste("Silhouette plot para k =", k),
x = "Muestras ordenadas por cluster",
y = "Coeficiente de silueta") +
scale_fill_manual(values = scales::hue_pal()(length(unique(sil_df$cluster)))) +
theme_minimal()
}
# Loop over different values of k
for (k in 2:10) {
km <- kmeans(data_matrix, centers = k, nstart = 25)
# Calculate average silhouette score for each k
ss <- silhouette(km$cluster, dist(data_matrix))
avg_sil <- mean(ss[, 3])
cat(sprintf("Para k = %d, el coeficiente de silueta es %.3f\n", k, avg_sil))
silhouette_scores <- c(silhouette_scores, avg_sil)
# Generate silhouette plots
print(plot_silhouette_custom(data_matrix, km$cluster, k))
}
# Coeficiente de silueta vs k
plot(2:10, silhouette_scores, type="b", pch=19, col="blue", xlab="Number of clusters", ylab="Silhouette Coefficient", main = "Silhouette Coefficient vs k")
# Storing Evaluation Metrics
wcss <- c()
# Loop Over k Values
for (k in 2:10) {
km <- kmeans(data_matrix, centers = k, nstart = 25)
# WCSS
wcss <- c(wcss, km$tot.withinss)
}
# Elbow Method Visualization (WCSS)
plot(2:10, wcss, type="b", pch=19, col="orange", xlab="Number of clusters", ylab="WCSS", main = "Elbow Method Visualization (WCSS)")
calinski <- c()
#  Loop Over k Values
for (k in 2:10) {
km <- kmeans(data_matrix, centers = k, nstart = 25)
# Calinski-Harabasz
calinski_val <- calinhara(data_matrix, km$cluster, k)
calinski <- c(calinski, calinski_val)
}
# Visualization
plot(2:10, calinski, type="b", pch=19, col="green", xlab="Number of clusters", ylab="Calinski-Harabasz Index", main = "Calinski-Harabasz")
davies <- c()
# Loop Over k Values
for (k in 2:10) {
km <- kmeans(data_matrix, centers = k, nstart = 25)
# Davies-Bouldin
int_idx <- intCriteria(data_matrix, as.integer(km$cluster), c("Davies_Bouldin"))
davies <- c(davies, int_idx$davies_bouldin)
}
# Visualization
plot(2:10, davies, type="b", pch=19, col="purple", xlab="Número de clusters", ylab="Davies-Bouldin Index", main = "Davies-Bouldin")
set.seed(42)
km <- kmeans(df_mall, centers = 6, nstart = 100, iter.max = 1000)
# nstart: Number of random initializations for the K-Means algorithm.
# 1000: Maximum number of iterations allowed per run to ensure convergence.
# Viewing Assigned Clusters
print(km$cluster)
# Add the cluster assignments to the original DataFrame.
df_mall$cluster <- as.factor(km$cluster)
# Centroids
centroides <- km$centers
kable(centroides, caption = "Centroids")
#Display the first 10 rows of the DataFrame with cluster labels.
head(df_mall, 10)
# Show the number of observations per cluster.
kable(table(df_mall$cluster), caption = "Observations per Cluster — Partition-Based Clustering")
#Renaming Centroid Columns
centroids <- as.data.frame(km$centers)
colnames(centroids) <- c("Age", "Income", "Score")
# 3D plot
fig <- plot_ly(data = df_mall,
x = ~Age,
y = ~Income,
z = ~Score,
color = ~cluster,
colors = "Set1",
type = "scatter3d",
mode = "markers")
# Adding Centroids Without Inheriting Previous Mappings
fig <- fig %>% add_trace(x = centroids$Age,
y = centroids$Income,
z = centroids$Score,
type = "scatter3d",
mode = "markers",
marker = list(size = 7, color = "black", symbol = "x"),
name = "Centroids",
inherit = FALSE)
fig
# Calculating Distances and Hierarchical Clustering (Ward’s Method)
d <- dist(df_mall, method="euclidean")
hc <- hclust(d, method="ward.D2")
# Cutting the Dendrogram into k = 6 Clusters
grupos <- cutree(hc, k=6)
kable(table(grupos), caption = "Observations per Cluster — Hierarchical Clustering")
library(ggplot2)
# Dendrogram Visualization Highlighting k Clusters
k_opt <- 6
fviz_dend(
hc, k = k_opt,
rect = TRUE,               # Rectangles around the 6 clusters to highlight them clearly.
show_labels = FALSE,       # Optionally hide row labels for clarity (e.g., labels = FALSE).
cex = 0.5,                 # Adjust text size if row labels are displayed (labels = TRUE).
main = "Dendrograma"
)
#install.packages("dbscan")
library(dbscan)
# Data Scaling
data_scale <- scale(df_mall[, c("Age", "Income", "Score")])
# Apply DBSCAN
modelo_db <- dbscan(data_scale, eps = 0.52, minPts = 4)
modelo_db$cluster  # Cluster Labels for Each Point
kable(table(modelo_db$cluster), caption = "Observations per Cluster — DBSCAN")
# Cluster Plot
plot(data_scale, col = modelo_db$cluster + 1L, pch = 19, main = "Clusters DBSCAN")
library(factoextra)
fviz_cluster(list(data = data_scale, cluster = modelo_db$cluster),
geom = "point",
palette = "jco",
main = "DBSCAN Clustering")
#install.packages("fpc")
#install.packages("clusterCrit")
library(knitr)
metricas <- data.frame(Metric  = c("Silhouette ", "Elbow", "Calinski-Harabasz", "Davies-Bouldin"),
Criterion  = c("Maximum value","Elbow point", "Maximum value","Minimum value"))
kable(metricas, caption = "Optimal Number of Clusters (k)")
library(fpc)
library(clusterCrit)
silhouette_scores <- c()
# Transform data into a numeric matrix of type double
data_matrix <- as.matrix(df_mall)
storage.mode(data_matrix) <- "double"
# Function to plot silhouette plots
plot_silhouette_custom <- function(data, clusters, k) {
dist_matrix <- dist(data)
sil <- silhouette(clusters, dist_matrix)
sil_df <- as.data.frame(sil[, 1:3])
colnames(sil_df) <- c("cluster", "neighbor", "sil_width")
sil_df$cluster <- as.factor(sil_df$cluster)
# Add an index for sorting
sil_df <- sil_df %>%
arrange(cluster, -sil_width) %>%
mutate(index = row_number())
ggplot(sil_df, aes(x = index, y = sil_width, fill = cluster)) +
geom_bar(stat = "identity", width = 1, color = "black", show.legend = FALSE) +
geom_hline(aes(yintercept = mean(sil_width)), color = "red", linetype = "dashed") +
labs(title = paste("Silhouette plot para k =", k),
x = "Muestras ordenadas por cluster",
y = "Silhouette Coefficient") +
scale_fill_manual(values = scales::hue_pal()(length(unique(sil_df$cluster)))) +
theme_minimal()
}
# Loop over different values of k
for (k in 2:10) {
km <- kmeans(data_matrix, centers = k, nstart = 25)
# Calculate average silhouette score for each k
ss <- silhouette(km$cluster, dist(data_matrix))
avg_sil <- mean(ss[, 3])
cat(sprintf("Para k = %d, el coeficiente de silueta es %.3f\n", k, avg_sil))
silhouette_scores <- c(silhouette_scores, avg_sil)
# Generate silhouette plots
print(plot_silhouette_custom(data_matrix, km$cluster, k))
}
library(fpc)
library(clusterCrit)
silhouette_scores <- c()
# Transform data into a numeric matrix of type double
data_matrix <- as.matrix(df_mall)
storage.mode(data_matrix) <- "double"
# Function to plot silhouette plots
plot_silhouette_custom <- function(data, clusters, k) {
dist_matrix <- dist(data)
sil <- silhouette(clusters, dist_matrix)
sil_df <- as.data.frame(sil[, 1:3])
colnames(sil_df) <- c("cluster", "neighbor", "sil_width")
sil_df$cluster <- as.factor(sil_df$cluster)
# Add an index for sorting
sil_df <- sil_df %>%
arrange(cluster, -sil_width) %>%
mutate(index = row_number())
ggplot(sil_df, aes(x = index, y = sil_width, fill = cluster)) +
geom_bar(stat = "identity", width = 1, color = "black", show.legend = FALSE) +
geom_hline(aes(yintercept = mean(sil_width)), color = "red", linetype = "dashed") +
labs(title = paste("Silhouette Plot for k =", k),
x = "Points Ordered by Cluster",
y = "Silhouette Coefficient") +
scale_fill_manual(values = scales::hue_pal()(length(unique(sil_df$cluster)))) +
theme_minimal()
}
# Loop over different values of k
for (k in 2:10) {
km <- kmeans(data_matrix, centers = k, nstart = 25)
# Calculate average silhouette score for each k
ss <- silhouette(km$cluster, dist(data_matrix))
avg_sil <- mean(ss[, 3])
cat(sprintf("For k = %d, the average silhouette coefficient is %.3f\n", k, avg_sil))
silhouette_scores <- c(silhouette_scores, avg_sil)
# Generate silhouette plots
print(plot_silhouette_custom(data_matrix, km$cluster, k))
}
library(ggplot2)
# Dendrogram Visualization Highlighting k Clusters
k_opt <- 6
fviz_dend(
hc, k = k_opt,
rect = TRUE,               # Rectangles around the 6 clusters to highlight them clearly.
show_labels = FALSE,       # Optionally hide row labels for clarity (e.g., labels = FALSE).
cex = 0.5,                 # Adjust text size if row labels are displayed (labels = TRUE).
main = "Dendrogram"
)
